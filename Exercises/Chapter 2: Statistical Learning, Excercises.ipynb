{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T20:39:35.277540Z",
     "start_time": "2018-08-02T20:39:35.272433Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Learning Excercises\n",
    "\n",
    "#### 1. For each of parts (a) through (d), indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible method. Justify your answer.\n",
    "\n",
    "***(a) The sample size n is extremely large, and the number of predictors p is small.***\n",
    "\n",
    ">In this case, I would favor a more flexible method because it can make use of the large n to glean extra information with minimal risk (given the low number of predictors, so less opportunity for overfitting)\n",
    "\n",
    "***(b) The number of predictors p is extremely large, and the number of observations n is small.***\n",
    "\n",
    ">In this case, where models are particular susceptible to overfitting/learning noise in the data, I would favor a less flexible method.\n",
    "\n",
    "***(c) The relationship between the predictors and response is highly non-linear.***\n",
    "\n",
    ">In this case, a more flexible model that does not make any assumptions of an underlying functional form would likely outperform an inflexible method.\n",
    "\n",
    "***(d) The variance of the error terms, i.e. σ2 = Var(ε), is extremely high.***\n",
    ">I would expect an inflexible model to perform better here, as the more flexible models may be increasingly more likely to overfit the noise as the variance increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T16:30:01.113933Z",
     "start_time": "2018-08-01T16:30:01.099466Z"
    }
   },
   "source": [
    "#### 2. Explain whether each scenario is a classification or regression problem, and indicate whether we are most interested in inference or prediction. Finally, provide n and p.\n",
    "\n",
    "***(a) We collect a set of data on the top 500 firms in the US. For each firm we record profit, number of employees, industry and the CEO salary. We are interested in understanding which factors affect CEO salary.***\n",
    "\n",
    ">This is regression; the target, CEO salary, is a continuous variable.  We are interested in inference, meaning we are less concerned with the particular predictions, and more with the factors associated with inreased or decreased CEO salary. n = # of firms = 500; p = # of predictors = 3\n",
    "\n",
    "***(b) We are considering launching a new product and wish to know whether it will be a success or a failure. We collect data on 20 similar products that were previously launched. For each product we have recorded whether it was a success or failure, price charged for the product, marketing budget, competition price, and ten other variables.***\n",
    "\n",
    ">This is classication; we are trying to make a binary determination of success or failure.  The goal here is prediction since we are more interested in the predictions themselves and less about the relationship between features and the output. n = 20, p = 13\n",
    "\n",
    "***(c) We are interested in predicting the % change in the USD/Euro exchange rate in relation to the weekly changes in the world stock markets. Hence we collect weekly data for all of 2012. For each week we record the % change in the USD/Euro, the % change in the US market, the % change in the British market, and the % change in the German market.***\n",
    "\n",
    ">This is regression for prediction.  We are trying to predict % change, a continuous value, and the goal is to predict, not understand the exact relationship between features and target. n = 56 (one observation per week), p = 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. We now revisit the bias-variance decomposition.\n",
    "\n",
    "***(a) Provide a sketch of typical (squared) bias, variance, training er- ror, test error, and Bayes (or irreducible) error curves, on a sin- gle plot, as we go from less flexible statistical learning methods towards more flexible approaches. The x-axis should represent the amount of flexibility in the method, and the y-axis should represent the values for each curve. There should be five curves. Make sure to label each one.***\n",
    "\n",
    "<img src=\"../figures/2_3a.jpg\" alt=\"flexibility\" width=\"600px\"/>\n",
    "\n",
    "***(b) Explain why each of the five curves has the shape displayed in part (a).***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. You will now think of some real-life applications for statistical learning.\n",
    "\n",
    "***(a) Describe three real-life applications in which classification might be useful. Describe the response, as well as the predictors. Is the goal of each application inference or prediction? Explain your answer.***\n",
    "\n",
    "***(b) Describe three real-life applications in which regression might be useful. Describe the response, as well as the predictors. Is the goal of each application inference or prediction? Explain your answer.***\n",
    "\n",
    "***(c) Describe three real-life applications in which cluster analysis might be useful.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What are the advantages and disadvantages of a very flexible (versus a less flexible) approach for regression or classification? Under what circumstances might a more flexible approach be preferred to a less flexible approach? When might a less flexible approach be preferred?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Describe the differences between a parametric and a non-parametric statistical learning approach. What are the advantages of a para- metric approach to regression or classification (as opposed to a non- parametric approach)? What are its disadvantages?\n",
    "\n",
    ">A parametric model the problem to learning a set of parameters of a particular function (e.g. linear regression coefficients), whereas non-parametric approaches do not assume a particular functional form.\n",
    "Advantages of a parametric approach are that they can have significantly lower variance (because the assumption of a particular functional form will make the model less sensitive to particular data points or outliers, decreasing model variance).  A disadvantage is the increased bias; assuming a certain functional form limits the complexity of decision boundaries, and your assumed form may be insufficient for some problems.  \n",
    ">\n",
    ">A non-parametrics approach may be preferred if the data is highly non-linear/decision boundary is highly irregular, or we have large amounts of data and a relatively small number of predictors.  A disadvantage of these approaches can be high variance and greater likelihood of overfitting as the model is flexible enough to learn from noise in the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. The table below provides a training data set containing six observa- tions, three predictors, and one qualitative response variable.\n",
    "\n",
    "|Obs. |X1 |X2| X3| Y|\n",
    "|---|---|---|---|---|\n",
    "|1| 0|3|0| Red|\n",
    "|2| 2|0|0| Red|\n",
    "|3| 0|1|3| Red|\n",
    "|4| 0|1|2| Green|\n",
    "|5| −1|0|1| Green|\n",
    "|6| 1|1|1|Red|\n",
    "\n",
    "***(a) Compute the Euclidean distance between each observation and the test point, X1 =X2 =X3 =0.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T20:36:46.439148Z",
     "start_time": "2018-08-02T20:36:46.408775Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obs.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X1  X2  X3      Y\n",
       "Obs.                   \n",
       "1      0   3   0    Red\n",
       "2      2   0   0    Red\n",
       "3      0   1   3    Red\n",
       "4      0   1   2  Green\n",
       "5     -1   0   1  Green\n",
       "6      1   1   1    Red"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = pd.DataFrame([\n",
    "    [1, 0, 3, 0, 'Red'],\n",
    "    [2, 2, 0, 0, 'Red'],\n",
    "    [3, 0, 1, 3, 'Red'],\n",
    "    [4, 0, 1, 2, 'Green'],\n",
    "    [5, -1, 0, 1, 'Green'],\n",
    "    [6, 1, 1, 1, 'Red']\n",
    "], columns=['Obs.', 'X1', 'X2', 'X3', 'Y']).set_index('Obs.')\n",
    "\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T20:40:14.839809Z",
     "start_time": "2018-08-02T20:40:14.835137Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_distance(training_data, new_sample):\n",
    "    distance = ((training_data[['X1', 'X2', 'X3']] - new_sample)**2).sum(axis=1).apply(np.sqrt)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T20:41:21.446386Z",
     "start_time": "2018-08-02T20:41:21.433343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance of point [0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Obs.\n",
       "1    3.000000\n",
       "2    2.000000\n",
       "3    3.162278\n",
       "4    2.236068\n",
       "5    1.414214\n",
       "6    1.732051\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_point = [0, 0, 0]\n",
    "\n",
    "print \"Euclidean distance of point {}\".format(test_point)\n",
    "get_distance(training_data, test_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***(b) What is our prediction with K = 1? Why?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T20:56:24.826330Z",
     "start_time": "2018-08-02T20:56:24.818989Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_pred(training_data, test_sample, k=1):\n",
    "    distances = get_distance(training_data, test_sample)\n",
    "    distances.sort_values(ascending=True, inplace=True)\n",
    "    print \"Distances from training data to test point\"\n",
    "    print distances\n",
    "    \n",
    "    return training_data.loc[distances.iloc[:k].index, 'Y'].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T20:57:07.536337Z",
     "start_time": "2018-08-02T20:57:07.521173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances from training data to test point\n",
      "Obs.\n",
      "5    1.414214\n",
      "6    1.732051\n",
      "2    2.000000\n",
      "4    2.236068\n",
      "1    3.000000\n",
      "3    3.162278\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Prediction for k = 1 is \"Green\"'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observation 5 is closest to test point, and Y='Green' for obs. 5\n",
    "\n",
    "'Prediction for k = 1 is \"{}\"'.format(get_pred(training_data, test_point, k=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***(c) What is our prediction with K = 3? Why?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T20:57:20.958944Z",
     "start_time": "2018-08-02T20:57:20.944107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances from training data to test point\n",
      "Obs.\n",
      "5    1.414214\n",
      "6    1.732051\n",
      "2    2.000000\n",
      "4    2.236068\n",
      "1    3.000000\n",
      "3    3.162278\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Prediction for k = 3 is \"Red\"'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 3 closest points are observation 5, 6, and 2. 6 and 2 have color Red, so the modal value/prediction is Red\n",
    "\n",
    "'Prediction for k = 3 is \"{}\"'.format(get_pred(training_data, test_point, k=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***(d) If the Bayes decision boundary in this problem is highly non- linear, then would we expect the best value for K to be large or small? Why?***\n",
    "\n",
    ">In this case, I would favor a smaller value of K, since increasing K smooths our prediction across many nearby points, which also has the effect of making the model _less_ sensitive to non-linear perturbations in the data (desirable if the data is very noisy, but not if there are truly significant non-linearities in the underlying problem)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
